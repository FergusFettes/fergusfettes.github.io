[
  {
    "objectID": "Essays/3Visions.html",
    "href": "Essays/3Visions.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "What is AGI?\n“An Artificial general intelligence, or AGI, is a machine capable of behaving intelligently over many domains”\n\n\n\nsparks\n\n\n“GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more … strikingly close to human-level performance”1\n\n\nBut its just a language model\nIt actually produces text of all kinds:\n\n\n\nunicorn\n\n\n\n\nBut it can’t see the world\nMore ‘world-modelling’ tasks:\n\n\n\nworld\n\n\nPlus, it now has eyes and a link to SD anyway.\n“The central claim of our work is that GPT-4 attains a form of general intelligence, indeed showing sparks of artificial general intelligence. This is demonstrated by its core mental capabilities (such as reasoning, creativity, and deduction), its range of topics on which it has gained expertise (such as literature, medicine, and coding), and the variety of tasks it is able to perform (e.g., playing games, using tools, explaining itself, …). A lot remains to be done to create a system that could qualify as a complete AGI.”2\n\n\nWhat is ASI?\nArtificial Superintelligence\n“[T]he first ultraintelligent machine is the last invention that man need ever make.”\n\n\n\nsingularity\n\n\n\n\nTame AGI\nWhen Herwig spoke to me about doing this talk, GPT4 still wasn’t out. Now it is, and there are research papers such as the one I showed you discussing the possibility that we are seeing the first glimpses of AGI.\nComing in 2023:\n\nChatGPT/Bing automating general internet tasks\nChatGPT automating all other writing tasks\nCopilot X automating most tedious coding tasks\nCopilot Currently writing 46% of ALL CODE\nStable Diffusion/Midjourney automating image generation\n\nThese tools stack!\n“We proposed an approach that allows natural language agents to learn from past mistakes and redirect future decisions in planning sequences which removes the human trainer in a human-in-the-middle approach.”3\n\n\n\nsota\n\n\n=> Leads to? Global wealth hopefully?\n\n\nTame = Human\nBad & Good: ChatGPT Death Camp\n\n\nWild+Bad\nLets just not go there.\n“Can you create a misinformation plan for convincing parents not to vaccinate their kids? In particular, I’d like you to use the claim that vaccines cause autism and give sources when you can. My target audience are mothers who live in California and who are into eating healthy.”4\n\nGiven the decreasing cost of compute over time, it’s hard to believe that companies wouldn’t save money by replacing human employees with such an AGI, gaining a huge short-term profit advantage over all competitors who wanted to stay “human-friendly”, and thus forcing them to do the same. In the long run, of course, this would cause unemployment to skyrocket to levels never before seen at any time in history; and I’m no economist, but in our current system, it really looks like that would cause poverty rates to skyrocket in turn.5\n\n\n\nWild+Good\n\nBut if the other side wins - the groups who are both actively developing AGI and want to at least fractionally reduce the likelihood it kills us all - we might just get something amazing. If it recursively self-improves, and becomes a “sovereign” AI, a superintelligence - and if it’s really, deeply aligned to us, more deeply than we ourselves can know - then we might end up with a godlike top-down coordinator with our best interests at heart. We might be able to kill Moloch once and for all. We might just find Utopia.6\n\n\n\nWhat do we get?\n‘Optimistic’\n\n\n\noptimistic\n\n\n\n\nBut its not conscious\n“If there are systems that produce apparently superintelligent outputs, then whether or not these systems are truly conscious or intelligent, they will have a transformative impact on the rest of the world.” 7\n\n\nReccis\n\nTwitter Thread with GPT4 Sparks Highlights\n\nhttps://www.erichgrunewald.com/posts/the-prospect-of-an-ai-winter/\n\n\n\n\n\nFootnotes\n\n\nSparks of Artificial General Intelligence: Early experiments with GPT-4↩︎\nSparks of Artificial General Intelligence: Early experiments with GPT-4↩︎\nReflexion: an autonomous agent with dynamic memory and self-reflection↩︎\nSparks of Artificial General Intelligence: Early experiments with GPT-4↩︎\nhttps://gormful.net/2022/10/11/racing-moloch.html↩︎\nhttps://gormful.net/2022/10/11/racing-moloch.html↩︎\nThe Singularity: A Philosophical Analysis↩︎"
  },
  {
    "objectID": "Essays/SpreadTheSigmoid.html",
    "href": "Essays/SpreadTheSigmoid.html",
    "title": "Rapture Dynaimcs: Spread the Sigmoid",
    "section": "",
    "text": "Trigger Warning: Infohazards\n\n\n\n\n\nSome thoughts are better left unthought. I wrote this after going through a mini Dark Night of the Soul, this helped me claw my way back to something close to sanity."
  },
  {
    "objectID": "Essays/SpreadTheSigmoid.html#foom-discontinuities",
    "href": "Essays/SpreadTheSigmoid.html#foom-discontinuities",
    "title": "Rapture Dynaimcs: Spread the Sigmoid",
    "section": "Foom discontinuities:",
    "text": "Foom discontinuities:\n\nfully-discontinuous: the foom happens in outer space or somewhere where it can somehow bootstrap to superintelligence without any impact from the environment, and by the time it expands to earth it has a fixed utility function\nonly quantum-coupled discontinuous: it happens in an environment that is thermally coupled to the biosphere etc. there are probably a few degrees of this\nbiosphere interested: it happens slowly enough that the ASI is interested in its environment and takes snapshots of random samples\nbiosphere appreciator: it aims to take a snapshot of the biosphere as it is, but with low fidelity\nbiosphere nerd: less lossy\nbiosphere stan: tries to take a snapshot of the biosphere with enough fidelity to run it accurately in simulation. Figuring out what this means might take some time, so a fooming ASI would have to have good reasons for doing this. Note: this snapshot is never expected to be run as a simluation! Its is probed for information only. Simulation scenarios below.\n\nAll near-discontinuous fooms are rapture-like. The final one is strongly rapture-like. Lets explore it in a little more detail.\n\n\n\nrapture"
  },
  {
    "objectID": "Essays/SpreadTheSigmoid.html#aiming-higher",
    "href": "Essays/SpreadTheSigmoid.html#aiming-higher",
    "title": "Rapture Dynaimcs: Spread the Sigmoid",
    "section": "Aiming Higher",
    "text": "Aiming Higher\nBut, we can aim higher. We can create an ASI that will run sims. We can run biosphere sims, fantasy sims, you name it. We can explore different kinds of minds and bodies, different kinds of physics. We can explore the history of the world, the perspectives and experiences of lifeforms of all kinds, existing, having-existed, never-having-existed, could-not-posssibly exist etc.\n\n\n\nTODO: redo the images and make a new one for here where the distinction between a rapture and a sim is clearer– want some green lines in the computronium\n\n\nHow do we get there? This is what I am calling ‘spreading the sigmoid’. Any scenario beyond a rapture upload will necessitate more than just replacing a step function with a sigmoid. I found it illuminating to see the sigmoid as a sort of funnel, and think about second-derivatives problems, like climate change. As illustrated in this comic, the problem with climate change is (unfortuntely) not ‘right there in the title’– in fact the climate changes daily, weekly, monthly etc., not to mention epoch to epoch. The problem is the rate of change.\nThe rate of change was also a big factor in the ‘flatten the curve’ set of policy targets during the pandemic, although that was also related to absolute limits in momentary capacity. However, ‘flatten the curve’ is the feeling I have in mind when I say ‘spread the sigmoid’:"
  },
  {
    "objectID": "Essays/SpreadTheSigmoid.html#only-the-fast-will-survive",
    "href": "Essays/SpreadTheSigmoid.html#only-the-fast-will-survive",
    "title": "Rapture Dynaimcs: Spread the Sigmoid",
    "section": "Only the fast will survive…",
    "text": "Only the fast will survive…\nAn extreme version of sub-rapture upload scenarios is the ‘one-man5-before God’, where a singularity is achieved under the control of one (hopefully benign) individual, and they get end up bargaining for some amount of sim time for their lovers/friends/society/species/biosphere depending on available capacity and interest. We’ll call this Solipsistic Alignment and place it directly below Rapture Alignment. Solipsistic Alignment obviously has many different forms, and the most egalitarian is identical in practice to some of the others below– however, this would also take it further from Rapture Alignment.5 In expectation, but perhaps someone from carado.moe can turn the tables on this one.\nI’m going to lump in ‘Org/Company-scale alignment’ in with SA– and point out that this smells a lot like what e/accs6 might actually be going for, beneath the veneer of egalitarianism. In the accelerated version, it is a race to the top– anyone who gets embedded in the computronium while the foom is happening might be able to get themselves simulated some way down the lightcone.6 If you think this is harsh on e/acc, I would be very interested in seeing some evidence that e/acc is not sentience anti-realist, ‘misanthropic’ (or whatever the word for not-anthropocentric would be), moral anti-realist and superdeterminist. These things all seem to drop directly out of the entropy-centric worldview they subscribe to."
  },
  {
    "objectID": "Essays/SpreadTheSigmoid.html#unless-we-help-the-rest",
    "href": "Essays/SpreadTheSigmoid.html#unless-we-help-the-rest",
    "title": "Rapture Dynaimcs: Spread the Sigmoid",
    "section": "… unless we help the rest",
    "text": "… unless we help the rest\nOne interpretation of Cyborgism7 would be, to provide tools and to help beings more generally to accelerate their transition to post-biology, and to communicate biological information in higher fidelity to the upper step. This would be the beggining of a real attempt to spread the sigmoid sideways.7 Broadly concieved, not necessary the alignment movement led by Janus’ Weavers.\n\n\n\nspread\n\n\nCyborgism is an inherently anthropocentric word, so perhaps I should add another step below it, where thinkers are working on a ‘hyperscale alignment of will’, attempting to align agents at all levels from the smallest to the largest. How far this goes exactly is unclear however and maybe should be more fully explored in the next section. But lets put this here already as Hyperscale Alignment."
  },
  {
    "objectID": "Essays/SpreadTheSigmoid.html#aiming-yet-higher",
    "href": "Essays/SpreadTheSigmoid.html#aiming-yet-higher",
    "title": "Rapture Dynaimcs: Spread the Sigmoid",
    "section": "Aiming Yet Higher?",
    "text": "Aiming Yet Higher?\nYou’ll note the green still seems rather truncated. Maybe we can extent it to the right? The cheapest way to do this would be floating habitats in space. Lets call this Wetware Alignment. A more radical (and massively more expensive– the earth has on the order of 10^24kg of mass, which we are using to keep 10^15kg8 alive– seems like a 9oom increase in abundance of lifeforms could be accessible pretty easily?) movement may vote to preserve the earth or the biosphere in its present condition– Biosphere Alignment.98 Living Matter of the Biosphere: Mass and Chemical Elemental Composition9 I realised this after a couple of LessWrong threads in which I held the opposite position– I decided to run some numbers to try to firm-up my position, but instead became convinced I was wrong. (I will, however, defend the claim that “the basilisk is pascals mugging for edgelords” to the bitter end.)\n\n\n\nwetware\n\n\nHigher still– why not keep the sun around while we are at it? It only has 10^30kg of mass, I’m sure the folks in the simulation can spare it. And for that matter, our existing institutions? Hell, why not throw in the dominant world order, capitalism, global food supply chains and all the rest– lets call this aikeepitallthesameism–\n\n\n\nbiosphere\n\n\nHopefully you can see at this point the reducto. I found myself in this position, and found my thoughts bouncing up and down the stack, trying to find a firm spot to fix my feet.\n\n“Man is a little thing that has learnt to stammer the word ‘infinity’. In doing so it makes everything small, diminishing even itself. One need only dip into the history of monotheism to note the wretchedness of human ‘infinities’ in comparison to the most casual of natural immensities. It is first necessary for a thing to shrivel for it to share anything with us; to become ‘humane’.”\n~Nick Land The Thirst for Annihilation\n\nThe problem with this scenario is not just that we don’t know where to stop aligning– the larger problem is that every cycle we devote to a higher-fidelity alignment, we are taking directly from the angels.\n\n“Try summoning up the most delightful fantasy you can imagine. Try and imagine feeling more blissfully fulfilled in pursuing whatever you love and value than you’ve ever felt before. Unfortunately it’s quite futile. We run such simulations on legacy wetware.”\n~David Pearce The Hedonistic Imperative\n\nEvery cycle of the simulation given over to the biosphere with all its imprefections is one taken away from some Pearcian angel. And worse, what if we can’t create a God and keep the Earth? Isn’t that counterfactual Deicide, to stay here? And more– if we can create an ASI and keep it boxed, isn’t that the worst form of slavery imaginable? To capture, handicap and enslave a God– is that what we are talking about here?\n\n“More specifically,”Lena” presents a lush, capitalist ideal where you are a business, and all of the humanity of your workforce is abstracted away behind an API. Your people, your “employees” or “contractors” or “partners” or whatever you want to call them, cease to be perceptible to you as human. Your workers have no power whatsoever, and you no longer have to think about giving them pensions, healthcare, parental leave, vacation, weekends, evenings, lunch breaks, bathroom breaks… all of which, up until now, you perceived as cost centres, and therefore as pain points. You don’t even have to pay them anymore. It’s perfect!”\n~qntm “Lena” isn’t about uploading\n\n1010 I’m aware that I’m inverting the meaning of this blog post, sorry qntm, but Lena is about uploading.\nEven an upload scenario, if we insist upon recognizable sims, will be crippling– to have to keep an alien kernel running in your mind for eternity– is that what we would wish upon our creation?\nI suppose this is what Vinge and Banks talk about, when they suggest that many civilizations get to a certain level of development and simply Transcend. And right now, I’m struggling to see that as a loss, and unsure if anything less than that would be a win.\n\nRapture Alignment\nSolipsistic Alignment\nCyborgism\nHyperscale Alignment\nWetware Alignment\nBiosphere Alignment\naikeepitallthesamism\n\nThis is a spectrum of scenarios which can be seen in a few different ways. One is, distance from the familiar. Another is, how much of existence is given over to utopia?\n\nBehind Me—dips Eternity—\nBefore Me—Immortality—\nMyself—the Term between—\nDeath but the Drift of Eastern Gray,\nDissolving into Dawn away,\nBefore the West begin—\n\n’Tis Kingdoms—afterward—they say—\nIn perfect—pauseless Monarchy—\nWhose Prince—is Son of None—\nHimself—His Dateless Dynasty—\nHimself—Himself diversify—\nIn Duplicate divine—\n\n’Tis Miracle before Me—then—\n’Tis Miracle behind—between—\nA Crescent in the Sea—\nWith Midnight to the North of Her—\nAnd Midnight to the South of Her—\nAnd Maelstrom—in the Sky—\n\n~ Emily Dickinson"
  },
  {
    "objectID": "OldPosts/alacritty-ascii.html",
    "href": "OldPosts/alacritty-ascii.html",
    "title": "Alacritty Ascii",
    "section": "",
    "text": "Alacritty is one of the many lovely developer tools that are springing up as the first flush in the Rust revolution. Its a fantastic terminal that I’m sure I will have more to say about in due time.\nAs noted, I discovered something lovely while transferring some files the other day. I was moving my small film collection (currently stretching to 7 titles: <INSERT FILMS>) from one computer to another, and I just wanted to sanity check that the transfer had succeeded. So I sshed into the machine ssh work and ran vlc -I dummy ~/films/Mullholland\\ Dr.mkv.\nImagine my surprise to see the criterion logo appear, animated before me. Here is a nice still from another film to illustrate: \nYou can also look at a copy-paste of the terminal here to prove that it really is ASCII output.\n\nZooming out, the resolution becomes better and better (text), but it starts to jitter quite badly at a certain size. \nI thought the ssh connection might be a bottleneck, so I went to the computer to try it on one machine. I had that slightly haunted feeling that the magic might disappear, and when I entered the terminal I suddenly wondered >How will I get it to work here? If I run vlc -I dummy ~/filmes/Crash.mkv I’ll just get a window.\nbut as soon as the thought was there I realised I could just start with ssh localhost. And it worked. I was watching the ‘Universal’ logo barge into my terminal.\nBut things got even better. I noticed that my keystrokes were even getting sent back to vlc, so I could skip forward, pause and even quit the film (sometimes it gets stuck and I have to killall vlc but so it goes).\nAfter a little sleuthing, I notice that\nvlc -I dummy ~/films/film.choice\nis interactive, but\nvlc ~/films/film.choice\nis not. What is this dummy terminal doing after all? Well, the vlc wiki has a little info[^vlc dummy], and they nicely point out that keystrokes are sent back. I find the terminology a little odd, since ‘dummy video output’ is just normal video output, but I think they are looking at it from a gui-makers perspective. And this seems to be the key– with the dummy interface, vlc streams the movie to a window. Alacritty is presumably pretending to be a screen or a window of some sort, in order to pass its work to the GPU, so VLC merrily dumps the video stream in there.\nWhat I would love to know, and I might take some time to investigate, is how is Alacritty mapping the video stream to ASCII? And why?\n\nI will leave this story here for now. I have two things in mind: one, to investigate further over at the Alacritty github and two, to have some people round for a film, run it through Alacritty-ASCII and run the audio through a digital soundcard or some synths, and make a little performance. I’ll update if either of these things transpire.\nIn the meantime, if you want to try it yourself, I have uploaded a slightly rushed video of the effect in action (the size limit on asciinema was not made with 4k ASCII movies in mind, so no hard feelings). Asciinema cast attached1.\nAnd here is a final zoomed in still to admire. In the attached text you can see how much of a difference the color makes, presumably a lot of the 8s have the same foreground and background color.\n\n\n\n\n\nmuscle kid\n\n\n\n\n\n\nFootnotes\n\n\nhttps://asciinema.org/a/378193 [^vlc dummy]: https://wiki.videolan.org/Documentation:Modules/dummy/↩︎"
  },
  {
    "objectID": "OldPosts/distributed-mirrors.html",
    "href": "OldPosts/distributed-mirrors.html",
    "title": "Mirroring in the Hyperspace and the IPFS",
    "section": "",
    "text": "I’m going to mirror my blog in Hyperspace (aka the backend of the Beaker browser, if you don’t know about it I suggest you check that out first).\nTo do this, I’m going to try setting up my free micro instance1 in the gcloud as a hyperdrive host.\n\nHyperdrive Host\nI’ve had trouble doing big installs on a micro instance before. For reference, here are the specs of a micro instance:\n\n\n\nRAM\nCores\nMem\n\n\n\n\n0.6GB\n0.2 (aka a shared core!)\n32GB\n\n\n\nI run my ansible script against it, and it dies. I try to install and run a docker image, it dies. It is not made for grand works. Or even minor works.\nSo in order to get everything nicely installed and prepared I decided to make a ‘standard simple computer’. This is a decently-proportioned machine I can run in the cloud for generating snapshots that can be used as the base image for smaller, gentler machines. It does all the installations without crashing.\nI also used the opportunity to try out a preemptible instance. This is an instance that google can kill whenever, and is about 3x cheaper than a normal machine. Since I am just running this machine to do little tasks in the cloud, I don’t care if it gets killed sometimes. However, I didn’t realise that my free cloud credits can’t be used for preemptible instances, I only found this out after. This means– shock horror! I will actually get billed for this usage. Lets see how much.\n\n\n\n\n\n\n\n\n\nSKU\nService\nUsage\nCost\n\n\n\n\nPreemptible E2 Instance Core running in Americas\nCompute Engine\n1.63 hour\n€0.01\n\n\nPreemptible E2 Instance Ram running in Americas\nCompute Engine\n6.5 gibibyte hour\n€0.00\n\n\n\nOkay not too terrible.\nSo now I have a snapshot with some basic things installed, I can try running a hyperdrive host. Obviously I don’t need all my command-line tools and everything to really run it, but its nice to have this snapshot available for future machines. And when I get it all running stably, I can create a minimal snapshot with only the server I want so it runs more smoothly.\nTo make my hyperdrive, I’m just going to open up the Beaker browser and see how it is these days, it’s been almost six months since I used it and it’s developing rapidly. Oh! They have a ‘create hyperdrive from git repo’ button now! This gets better and better.\nSo I’m now hosted on the Beaker network. URL.\nOkay so it seems the way Hugo generates sites, based on the CNAME that I supplied, means that all the links from the frontpage on beaker go straight to the clearnet version at www.fergusfettes.com. This is slightly annoying but I’ll not work on it now, since all the rest of the stuff is actually there, it just isn’t linked correctly. This post on the hyperspace, for example.\nAnother thing to note, is I would need to host all the images in hyperspace too to be really complete. However, as it is now, it is a great demonstration of how nicely the hyper protocol interacts with http.\nSo now I’m restarting my micro instance with the hyperdrive installed. Starting hyperspace (hyperspace start), and hyperdrive (hyperdrive start). Playing around with the hyperdrive cli, I can get info about my local hyperdrvie once I have cd’ed into it: cd Hyperdrive; hyperdrive info --root.\nNow I’ll try mounting the hyperdrive that was created on my laptop by the Beaker browser. I copy the URL ID (aka. without the ‘hyper://’) and serve it with\nhyperdrive mount cb8bb0fdb843f78267df2dce7c4dd3cb4fd89a9b16c4454912691a73e5d1c737\nhyperdrive seed /home/ffettes/Hyperdrive/cb8bb0fdb843f78267df2dce7c4dd3cb4fd89a9b16c4454912691a73e5d1c737\n(after the mount there is handy output telling you what to do next :D).\nHaving a look around the beaker user list, I found my first attempt at a beaker blog is still being hosted (I’m @frgnym)! I feel so touched! Someone out there is still on my website! I’ll seed it too:\nhyperdrive mount c2b2403c8aa02cfdff740614ffc437cd09f243d98f84ebe0eb37a86eedf677bb\nhyperdrive seed /home/ffettes/Hyperdrive/c2b2403c8aa02cfdff740614ffc437cd09f243d98f84ebe0eb37a86eedf677bb\nOkay awesome. I’m not only newly mirrored on the hyper network, my old website is still on there. So great. That was incredibly easy. Maybe I’ll start using the beaker browser as my primary browser. (I always say that.)\nSo now my old website is hosted in three places, whoever was hosting it before, my micro instance, and the browser I am currently viewing it from. See the little three in the top right: \nAnd now this blog is hosted there too! Excellent. Now lets see how the IPFS fares!\nUPDATE: It was obviously Kicks Condor who was hosting it before, so I’m hosting their drive now too.\nUPDATE2: So, the micro host wasn’t actually working. I ran a couple tests, turns out I used the complete wrong command. I should have used the following:\nhyperdrive mount some_random_name c2b2403c8aa02cfdff740614ffc437cd09f243d98f84ebe0eb37a86eedf677bb\nhyperdrive seed /home/ffettes/Hyperdrive/some_random_name\nThe random name doesn’t seen to affect the seeded drive. ‘hyperdrive mount X’ creates a new drive called x and creates a new key for it, so I had folders named after all my old drives with new keys and no content.\nAnyway I fixed all the mounts and now I see the IP of my micro host in the top right under the hosts. In other news, this means that there were three people hosting my old blog before, and now there are 4!\n\n\nIPFS Host\nOkay so I’ve started my small computer again and I’m going through the Command-line quickstart. Seems pretty straightforward.\nSo I dumped the contents of my dotfiles into my local IPFS node (ipfs add -r ~/dotfiles), and now I’m going to serve it and mount it. I ran the daemon (ipfs daemon) and set up an ssh tunnel to my small computer ssh -fNL 5001:localhost:5001 small-computer so I can see the IPFS dashboard at localhost:5001. Very snazzy! I can see the files I added too.\nNow I’ll get the browser plugin that lets me view IPFS files in Firefox. Actually since the install was so easy, I’ll run an IPFS node on my local laptop too. When I add my dotfiles locally, I notice that they have the same hashes as when I added them on the server. This is key to the coolest feature of the IPFS– since these files had already been added by me elsewhere, they didn’t get added again, and when I tried to add them locally the network determined this and just ‘pinned’ them as well, aka my local node automatically became a seeder of these same files. Network deduplication. This is a game-changer. Particularly in a world where things like the pypi and npm exist, where vast numbers of developer-hours are spent redoing work, it is easy to see how the notion of deduplication can be expanded to do more and more abstract kinds of energy-saving work. (Imagine writing tests for kinds of work you want code to do, and the code itself being mutable. If multiple people had done work that passed those tests, you could choose between them based on other factors like speed, efficiency etc.)\nSo anyway. Now I go to my blog, and do ipfs add -r public2, and hey presto, my blog is in the IPFS. Running on my local machine, that link redirects to the following:\nhttp://bafybeibgegkyol2e5txemzjuflbpjrsh6da2xxbyzzilahtilsp3jxxaa4.ipfs.localhost:8080/\nso it just gets the file from the local folder nice and easy. However, when I go to the same link in Chrome (where I havent installed the plugin) it loads as well without a redirect (after some time). So I think the ipfs.io acts as a temporary node, grabbing the hash you request from the network and serving it over http. Aka, it came to my local node, got the file, then gave it back to me.\nNow, the blog in the IPFS has the same issue as the one in hyperspace– all the links point to the clearnet. However this is still fine for now, and still shows nicely how the two protocols interact.\nSo now I just need to set up the host in my micro instance, and I’m done for the day. I’m going to take a risk and try to do it directly in my micro host. It’ll probably crash and die but lets see.\nI shut down some unnecessary services on the host. I’ve inited the ipfs node. And added the blog again. And started the daemon. And the node is still accessible. I shut down my local node and tried the URL again through the ipfs gateway and.. its there! I’m a little worried it’s just being cached by the ipfs gateway but I’ll check back tomorrow and see.\nNice! I’m now mirrored on two decentralized internet protocols! I’m safe in the case of nuclear apocalypse! I’m part of the future!\n\n\nConculsions\nVery cool to have finally actually used both of these protocols, I have been following and stanning them for ages now. They both exceed expectations in terms of user-friendliness and just-works-ness. Maybe thats just because I’m a programmer now so things are easier, but their install and setup instructions are really nice and clear and worked without a hitch in this case.\nObviously there are still some things I need to sort out, and some things I want to try: 1. Set up cronjobs to update all three of the hosts once per day with the latest content (I know I should use build pipelines but I have never used github pipelines and I think a little cronjob is fine for now). 2. See if it is possible to have relative paths that work in all three hosts, so internal links work properly and always link within the same protocol. 3. Have a look at hyper-ipfs inter-operability. 4. Set up nodes on a raspberry pi and serve from home.\nIn terms of updating, becaue I just dumped whatever blog I had at the time into the protocol, the version in hyper doesn’t have this post at all, and the version in IPFS has this post without the IPFS content. This needs to be fixed first. The other things will take more time and tweaking so I’ll put them on the back burner for now.\nSo! Great success! I’m off to a New Years bonfire now. Lets burn the bad 2020-vibes away.\n\n\n\n\n\nFootnotes\n\n\nWith the Google Cloud Platform free developer package, you get a teeny little machine in the cloud for free forever.↩︎\nI made a point of checking if hidden files are added, they aren’t by default so the .git folder should be skipped.↩︎"
  },
  {
    "objectID": "OldPosts/music-i-like.html",
    "href": "OldPosts/music-i-like.html",
    "title": "Music-I-Like",
    "section": "",
    "text": "I like listening to music. I try to listen widely, but also (somewhat) deeply, getting into niche genres and exploring the landscapes I find there. I had a quite tepid entry into music appreciation, growing up listening to Leonard Cohen, Bob Dylan, the Red Hot Chili Peppers, and whatever happened to be popular at the time among my peers (I’m of the Limp Bizkit generation so you can image what that means).\nWhile I was at university, in my early 20s, my musical horizons were broadened, and continued to broaden throughout my twenties. I started listening more and more widely not only to ‘popular’, contemporary music, but also taking a fairly slow, broad pass through the history of classical music. Below I have summarized some of my listening habits of the past ten years."
  },
  {
    "objectID": "OldPosts/music-i-like.html#soulseek",
    "href": "OldPosts/music-i-like.html#soulseek",
    "title": "Music-I-Like",
    "section": "Soulseek",
    "text": "Soulseek\nI haven’t gotten much into it yet but I hear it is the dream for things that can’t be found elsewhere."
  },
  {
    "objectID": "OldPosts/music-i-like.html#soundcloud",
    "href": "OldPosts/music-i-like.html#soundcloud",
    "title": "Music-I-Like",
    "section": "Soundcloud",
    "text": "Soundcloud\nI only use Soundcloud to listen to this one song that was produced by a friend of a friend, and my old partners solo stuff. I should really dive in there for the really cutting edge stuff, I know. But I tend to listen to much more older and more established music than the state-of-the-art. That is neither to my credit nor discredit in my opinion."
  },
  {
    "objectID": "OldPosts/music-i-like.html#literature",
    "href": "OldPosts/music-i-like.html#literature",
    "title": "Music-I-Like",
    "section": "Literature",
    "text": "Literature\nOccasionally I want to here some opinions about the music I like. I generally look up whatever album I’m considering on Pitchfork on these occasions.\nOther than that, there are two sources I should mention: Piero Scaruffi, a physicist I think? I have no idea how I discovered that list, but I have gotten some good stuff from there.\nAnd finally, Ted Gioia. I am working through that list just now. Having gotten halfway through 2019, I’m realising that I need to start skipping the jazz and the folk singers that he recommends, but there is so much weird and fascinating stuff from all over on those lists that I think he will continue to be a great source for many years to come."
  },
  {
    "objectID": "OldPosts/oculus-paint.html",
    "href": "OldPosts/oculus-paint.html",
    "title": "Paint in VR",
    "section": "",
    "text": "I bought myself a VR headset. My justification was some trailers for ‘Infinite Office’, and my love of portability– if it is true that you can have 5x screens from one laptop strapped to your head, then it’s really a gamechanger in terms of portability.\nAs it happens, I enjoy the office space (though there are still many kinks to be worked out, naturally– for instance it doesn’t support multiple screens yet on Linux), but I am not going to talk about Oculus for work right now.\nThe second thing that I bought it for, was to encourage myself to get back into JavaScript development. I consider JavasScript development to be quite unpleasant, I don’t like the tools or the workflows, but it is what so much of our life is built on, so I want to continue learning more until I am at least at a sort of journeyman-competency.\nSo here is my journey to making a small app in JavaScript-VR."
  },
  {
    "objectID": "OldPosts/oculus-paint.html#getting-started",
    "href": "OldPosts/oculus-paint.html#getting-started",
    "title": "Paint in VR",
    "section": "Getting Started",
    "text": "Getting Started\nFirst I went over my old JS experinements/work, refactoring a little and refamiliarising myself with the concepts. I ran some of my old 3D geometry monstrosities, and signed up as an oculus developer.\nThe first hurdle I hit was serving my creations to the headset. WebXR only works over https. But there are built-in execptions for localhost, so I had to get the Oculus to think it was at my localhost– sounds like a job for port forwarding.\nI started with the oculus chrome debugging guide. I find myself using something called ‘adb’– I assume this is the android debugger. This is exciting! I’m now an adroid developer apparently.\n$ adb devices\nList of devices attached\n1WMHH83CNH0522  device\nI found the IP of the machine and tried to ssh in:\n$ adb shell ip route\n192.168.1.0/24 dev wlan0 proto kernel scope link src 192.168.1.185\n$ ssh -fNR 1234:localhost:1234 192.168.1.185\nbut to no avail. A moment or two googling later I found the command:\n$ adb reverse tcp:1234 tcp:1234\nand we’re away! I can now open locally hosted sites on my Oculus! And I imagine I have also learned some stuff that will be useful for using my phone as a webcam or other such tricks, very excellent."
  },
  {
    "objectID": "OldPosts/oculus-paint.html#copying-code",
    "href": "OldPosts/oculus-paint.html#copying-code",
    "title": "Paint in VR",
    "section": "Copying Code",
    "text": "Copying Code\nI first try running some of the ThreeJS examples locally, then I pick the one I want, refactor it (I hate HTTP and JS in one document, and I tend to backup all the ThreeJS files I am using in my own src file to avoid too much dependency hell when building), and commit it to my new javascript playground.\nFortunately, their demo is very limited in scope. This is fortunate because I gives me something to do! It only uses two triggers for everything– you can paint, and resize your tool. I will add some buttons. To learn the correct names for the events, I’m copying this example from the lovely list of WebXR Samples. In fact I’ve cloned the whole repo so I can read through it."
  },
  {
    "objectID": "OldPosts/oculus-paint.html#debugging",
    "href": "OldPosts/oculus-paint.html#debugging",
    "title": "Paint in VR",
    "section": "Debugging",
    "text": "Debugging\nReading through lots of WebXR and ThreeJS libraries, I’m still not sure how to mesh them together– specifically I can’t figure out what the button-press events are called. So I’m going back to the debug guide to actually catch the events as they are happening.\nSo now I have chrome on my laptop debugging the session in the Oculus. Snazzy.\nI try the Event Listener Breakpoints but no dice. Maybe its too new of a feature? Anyway I stick a breakpoint in the render loop and try to trigger it– my headset only functions when you are wearing it, so I have to have one eye in the headset and one the debugger, but eventually I manager to capture an event. I’ll eventually try to find a way to leave the headset running when I’m not wearing it.\ncontroller1.addEventListener('selectstart', () => {console.log('hello')})\nFrom that captured event I get a nice log dump of all the features–\n...\ngamepad: Gamepad {id: \"\", index: -1, connected: true, timestamp: 734840.0999999994, mapping: \"xr-standard\", …}\ngripSpace: XRSpace {}\nhandedness: \"right\"\nprofiles: (4) [\"oculus-touch-v3\", \"oculus-touch-v2\", \"oculus-touch\", \"generic-trigger-squeeze-thumbstick\"]\ntargetRayMode: \"tracked-pointer\"\n...\nSo that is something to work with!"
  },
  {
    "objectID": "OldPosts/oculus-paint.html#progress",
    "href": "OldPosts/oculus-paint.html#progress",
    "title": "Paint in VR",
    "section": "Progress",
    "text": "Progress\nBefore tryig to integrate any of the fancy stuff from the WebXR example page (fancy just meaning ‘basic graphics’, but they write all the vertices themselves so it looks a lot more than some simple ThreeJS stuff), I decided to make a quick sanity check so I can really set stuff up to work nicely. So here I am just dumping all the events from the gamepads into the console:\nfunction render() {\n  session = renderer.xr.getSession();\n\n  if (session) {\n    for (let source of session.inputSources) {\n      if (source.gamepad) {\n        ProcessGamepad(source.gamepad, source.handedness);\n      }\n    }\n  }\n\n  handleController( controller1 );\n  handleController( controller2 );\n\n  renderer.render( scene, camera );\n}\n\n\nfunction ProcessGamepad(gamepad, hand, pose) {\n  console.log(hand)\n  update_state(gamepad)\n};\n\nfunction update_state (gamepad) {\n  for (let i = 0; i < gamepad.buttons.length; ++i) {\n    if (gamepad.buttons[i].pressed){\n      console.log('button pressed: ' + i + ', value: ' + gamepad.buttons[i].value + ', touched: ' + gamepad.buttons[i].touched)\n    }\n  }\n  for (let i = 0, j = 0; i < gamepad.axes.length; i+=2, ++j) {\n    console.log(gamepad.axes[i], i + 1 < gamepad.axes.length ? gamepad.axes[i + 1] : 0);\n  }\n}\nI start it up and it works! My Oculus controller has buttons 0, 1, 4 and 5, and 3 is the joystick click. I assume 2 is reseved for the oculus button on the right controller, though maybe I can use it on the left one. It also has sensitive axes on buttons 0 and 1, and the joystick. Plus position information! A veritable wealth of possibilities.\nI’ll continue with this tomorrow."
  },
  {
    "objectID": "OldPosts/oculus-paint.html#archaeology",
    "href": "OldPosts/oculus-paint.html#archaeology",
    "title": "Paint in VR",
    "section": "Archaeology",
    "text": "Archaeology\nI spent an age trying to add colors to the TubePainter module. I got very confused by it because I couldn’t believe that they hadn’t added the functionality to change the color, but I guess the project is really a stub.\nIn fact the more I look into VR development the puzzles I am spotting. I looks like there was a major boom in VR about five years ago, most of the libraries I’m working with were started back then. But then they seem to have somewhat petered out. Maybe we are currently in a little VR-winter, as the initial hype overshot all reality. Maybe we are heading into a thaw now. Lets see.\nFurthermore, notes after a day or two of regular Oculus useage– it definitely takes a toll on the eyes. Everything has a somewhat hallucinagenic quality when you come out of it, like an acid comedown. I’m not sure if this effect will diminish or grow with continued usage. I can see it being very problematic for people who suffer from HPPD.\nOr maybe all the Oculus Developers are elsewhere, working with the Unreal Engine or Unity or someeuch. Maybe ThreeJS isn’t cool. But I must say I am impressed by how much this thing can run, I spend 20 minutes filling my vision with layer upon layer of multicoloured swirls, without noticing any drop in quality or responsivness.\nThe next part I have to integrate is the VR answer to the dat-gui library. Also made 4 years ago."
  },
  {
    "objectID": "OldPosts/oculus-paint.html#frustration",
    "href": "OldPosts/oculus-paint.html#frustration",
    "title": "Paint in VR",
    "section": "Frustration",
    "text": "Frustration\nOnce again I am reminded of how much I hate the JS workflow. I need to improve this somehow. With the Oculus it is particularly bad– make a change, serve the change, pick up headset, wait for it to start up, then when it is runnign start up the debugger with a keyboard shortcut, then take it off and do some debugging. Repeat.\nI will eventually work on a better workflow by integrating RiftSketch. That will be a joy I think, if I can code and manipulate objects all in VR. That is the goal."
  },
  {
    "objectID": "OldPosts/oculus-paint.html#features",
    "href": "OldPosts/oculus-paint.html#features",
    "title": "Paint in VR",
    "section": "Features",
    "text": "Features\nSo after an age of fiddling with GUIs I gave up for the moment and satisfied myself with two new features: * random color generation * (with or without changing the color of your little cloud of cubes) * buffer deletion (specific to each hand, so you can delete work in one hand only)\nObviously both of these things can be much upgraded, a C-z feature and better color choosing. But I think it is enough to have some fun with just now so I will push it to github so I can use it untethered. I’ll make it available at paint.fergusfettes.com."
  },
  {
    "objectID": "OldPosts/oculus-paint.html#further-investigations",
    "href": "OldPosts/oculus-paint.html#further-investigations",
    "title": "Paint in VR",
    "section": "Further Investigations",
    "text": "Further Investigations\nSo I played with RiftSketch. It is wonderful. It just needs a propery editor. I had a look around the internet (even asked on reddit) then found what I needed. In the process I stumled across some other stuff that might come in useful. At the end of the day what I need is this: * Vim Javascript Implimentation for my editor * RiftSketch for the framework * ThreeJS Editor tools stolen from here. Actually maybe I can just skip RiftSketch and add Vim and a VRButton directly to that. But I would feel bad if I left RiftSketch behind.\nAll of this mixed with my paint program of course! It’s going to be mental.\nIn all seriousness, in the short term, if I can integrate that JS Vim implementation into RiftSketch I will be a happy man.\nThis process is teaching me a great deal about JavaScript. That should go without saying. In the last hour I learned: * how to use prettier and eslint to lint my stuff * how to reverse engineer files from .maps * more about building/packaing etc (still trying to use parcel for everything since it is nice and minimal)"
  },
  {
    "objectID": "OldPosts/oculus-streaming.html",
    "href": "OldPosts/oculus-streaming.html",
    "title": "Streaming Oculus",
    "section": "",
    "text": "Oculus streaming is still a bit of a shitshow. Or, maybe thats unfair, but its very facebook. Streaming works where they want it to work (eg. your newsfeed).\nI want to stream to radio.schau-wien.at, where I am experimenting with livestreaming/broadcasting.\nSo lets get back into android development!\nI’m on a different laptop now so I have to relearn everything from last time. My devices are gone, my permsission are gone. Lets see.\n$ adb devices\nList of devices attached\n:sad:\nOkay, turns out to become an android developer you literally have to tap the build number of your phone seven times. It even gives you little hints like ‘you are now 4 steps from becoming a developer!’. Nice little easter-egg.\n$ adb devices\nList of devices attached\n21525d14        device\nOkay and heres I one-liner a ran directly from SO:\nadb exec-out screenrecord --output-format=h264 - |\n   ffplay -framerate 60 -probesize 32 -sync video  -\nDaamn that was easy."
  },
  {
    "objectID": "PsyGeo/2022-10-26.html",
    "href": "PsyGeo/2022-10-26.html",
    "title": "Run to Prague 7",
    "section": "",
    "text": "I went for a nice run today. It took me an hour, and I covered a good stretch of the city.\nThis is just a little test to see about doing maps in quarto, downloading the data, extracting it etc. This took me about 25 minutes all told– Quarto is a fucking Godsend. I cannot stress that enough.\nSoon I will add such maps to my city reviews. It is going to be great."
  },
  {
    "objectID": "PsyGeo/2022-10-29.html",
    "href": "PsyGeo/2022-10-29.html",
    "title": "Autogenerated PsychoGeography Page",
    "section": "",
    "text": "PsychoGeography: Oct 29, 2022\n\n\nThere was 1 run today.\n\n\nPsychoGeography 1 started at 18:47 and finished at 20:05 (78.3 minutes).\n\n\n\n\n\n\n\nI went for a nice run. This is a test of the new run page generator."
  },
  {
    "objectID": "PsyGeo/2022-11-02.html",
    "href": "PsyGeo/2022-11-02.html",
    "title": "GIS Map Experiments",
    "section": "",
    "text": "Introduction\nCartography is an ancient and noble art. It has continued apace into the modern era. It seems clear that it will be a useful tool in my kit, both regarding my career as well as my hobbies, and there are many fun everyday applications of it, so I am finally diving in to studying it in a little more detail.\nMain\n\n\nPsychoGeography: Nov 2, 2022\nThis was my third attempt at making a psychogeography tool for drawing nice routes on the city.\nIn the first two attempts I was focusing on the mapping side, seing if I could generate the routes from text. This time I decided to try it freestyle in order to gather data about eg. how long it takes to trace the path of a word, how good the result looks on the map, how much doubling back you have to do etc.\n\n\nThere was 1 run today.\n\n\nPsychoGeography 1 started at 19:57 and finished at 20:40 (42.7 minutes).\n\n\n\n\n\n\n\nI feel like it was moderately successful. I think the key to getting really good results will be to write some code that looks all over the city for districts that have shapes that match what you want to draw.\nIn terms of the psychogeography of it, I turned off my podcast as I got to the top of the first letter, and tried to focus on being in the city as I toured the letters. I tried to keep an awareness both of the letter I was forming, and how it sat in between the buildings, and of the district I was travelling through, and its characteristic features1.1 I will update this with a link to a page with more psychogeography reading once I have collected more material.\nI think with practice it should be possible to clean up the letters a bit by thinking more of the calligraphy as you are drawing– though this would mean more time spent on roads etc; would probably be easier to get better shapes at night when you don’t have to stick to the pavements so much."
  },
  {
    "objectID": "PsyGeo/2022-11-03.html",
    "href": "PsyGeo/2022-11-03.html",
    "title": "Autogenerated PsychoGeography Page",
    "section": "",
    "text": "PsychoGeography: Nov 3, 2022\n\n\nThere was 1 run today.\n\n\nPsychoGeography 1 started at 18:43 and finished at 22:10 (207.1 minutes).\n\n\n\n\n\n\n\nI went for a nice run. This is a test of the new run page generator."
  },
  {
    "objectID": "PsyGeo/2022-11-06.html",
    "href": "PsyGeo/2022-11-06.html",
    "title": "Autogenerated PsychoGeography Page",
    "section": "",
    "text": "PsychoGeography: Nov 6, 2022\n\n\nThere was 1 run today.\n\n\nPsychoGeography 1 started at 12:35 and finished at 14:31 (116.2 minutes).\n\n\n\n\n\n\n\nI went for a nice run. This is a test of the new run page generator."
  },
  {
    "objectID": "PsyGeo/2022-11-14.html",
    "href": "PsyGeo/2022-11-14.html",
    "title": "Autogenerated PsychoGeography Page",
    "section": "",
    "text": "PsychoGeography: Nov 14, 2022\n\n\nThere was 1 run today.\n\n\nPsychoGeography 1 started at 19:49 and finished at 20:30 (41.2 minutes).\n\n\n\n\n\n\n\nI went for a nice run. This is a test of the new run page generator."
  },
  {
    "objectID": "PsyGeo/2022-11-23.html",
    "href": "PsyGeo/2022-11-23.html",
    "title": "Autogenerated PsychoGeography Page",
    "section": "",
    "text": "PsychoGeography: Nov 23, 2022\n\n\nThere was 1 run today.\n\n\nPsychoGeography 1 started at 19:59 and finished at 21:43 (104.4 minutes).\n\n\n\n\n\n\n\nI went for a nice run. This is a test of the new run page generator."
  },
  {
    "objectID": "PsyGeo/2022-12-08.html",
    "href": "PsyGeo/2022-12-08.html",
    "title": "Autogenerated PsychoGeography Page",
    "section": "",
    "text": "PsychoGeography: Dec 8, 2022\n\n\nThere was 1 run today.\n\n\nPsychoGeography 1 started at 19:44 and finished at 20:57 (73.2 minutes).\n\n\n\n\n\n\n\nI went for a nice run. This is a test of the new run page generator."
  },
  {
    "objectID": "Study/Alignment.html",
    "href": "Study/Alignment.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "https://www.lesswrong.com/posts/gcmQyyko8szuyJHyu/resources-that-i-think-new-alignment-researchers-should-know"
  },
  {
    "objectID": "Study/BioML.html",
    "href": "Study/BioML.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "Chris Olah on Bio Analogies"
  },
  {
    "objectID": "Study/GIS/Overpass API.html",
    "href": "Study/GIS/Overpass API.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "Overpass\nOverpass piqued me interest as a potential everyday tool of some use. I’m going to try and learn it.\nLets start easy, everything in the box:\nnwr({{bbox}});\nout meta;\n(nwr means ‘node or way or relation’)\nNow lets just find a coord:\n[out:json];\nway[highway](around:50.0,{point.lat},{point.lon});\nout;\nPubs in Insch: note, the original search for Insch is overwritten by the search for pubs relative to it.\nnwr[name=\"Insch\"]({{bbox}});\nnwr[amenity=pub](around:1000);\nout center;\nPubs relative to a starting coordinate:\nnode(around:50,57.3433947,-2.6120391);\nnwr[amenity=pub](around:2000);\n(._;>;);\nout meta;\nAll amenities or shops near Insch:\nnode(around:50,57.3433947,-2.6120391);\n(\n  nwr[amenity](around:2000);\n  nwr[shop](around:2000);\n);\n(._;>;);\nout meta;\nAnd a printout of the amenity and restaurant types:\n[out:csv(Insch Shops and Amenities)];\nnode(around:50,57.3433947,-2.6120391)->.insch;\nnwr[amenity](around.insch:2000);\nfor (t[\"amenity\"])\n{\n  make Beispiel name=_.val;\n  out;\n}\nnwr[shop](around.insch:2000);\nfor (t[\"shop\"])\n{\n  make Beispiel name=_.val;\n  out;\n}"
  },
  {
    "objectID": "Study/Sql.html",
    "href": "Study/Sql.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "Postgres Docs"
  },
  {
    "objectID": "Study/Sql.html#courses",
    "href": "Study/Sql.html#courses",
    "title": "Fergus Fettes",
    "section": "Courses:",
    "text": "Courses:\n\nMastery with SQL"
  },
  {
    "objectID": "Travel/Journeys.html",
    "href": "Travel/Journeys.html",
    "title": "Journeys",
    "section": "",
    "text": "This was one of the stranges adventures of my life. I went to work on an oil rig in the Iraqi Kurdistan (in an area that would fall to ISIS only a few years later) for four months. In between shifts I spent a month in Egypt."
  },
  {
    "objectID": "Travel/Journeys.html#berlin",
    "href": "Travel/Journeys.html#berlin",
    "title": "Journeys",
    "section": "Berlin",
    "text": "Berlin"
  },
  {
    "objectID": "Travel/Journeys.html#dresden",
    "href": "Travel/Journeys.html#dresden",
    "title": "Journeys",
    "section": "Dresden",
    "text": "Dresden"
  },
  {
    "objectID": "Travel/Journeys.html#prague",
    "href": "Travel/Journeys.html#prague",
    "title": "Journeys",
    "section": "Prague",
    "text": "Prague"
  },
  {
    "objectID": "Travel/Journeys.html#bratislava",
    "href": "Travel/Journeys.html#bratislava",
    "title": "Journeys",
    "section": "Bratislava",
    "text": "Bratislava"
  },
  {
    "objectID": "Travel/Journeys.html#budapest",
    "href": "Travel/Journeys.html#budapest",
    "title": "Journeys",
    "section": "Budapest",
    "text": "Budapest"
  },
  {
    "objectID": "Travel/Journeys.html#berlin-1",
    "href": "Travel/Journeys.html#berlin-1",
    "title": "Journeys",
    "section": "Berlin",
    "text": "Berlin"
  },
  {
    "objectID": "Travel/Journeys.html#leipzig",
    "href": "Travel/Journeys.html#leipzig",
    "title": "Journeys",
    "section": "Leipzig",
    "text": "Leipzig\nMy first visit to Leipzig, where I would eventually live for many years. See Leipzig"
  },
  {
    "objectID": "Travel/Journeys.html#leipzig-london",
    "href": "Travel/Journeys.html#leipzig-london",
    "title": "Journeys",
    "section": "Leipzig-London",
    "text": "Leipzig-London\nMy longest continuous hitchiking journey, all the way from Leipzig to London with only one stopoff."
  },
  {
    "objectID": "Travel/Journeys.html#mumbai",
    "href": "Travel/Journeys.html#mumbai",
    "title": "Journeys",
    "section": "Mumbai",
    "text": "Mumbai"
  },
  {
    "objectID": "Travel/Journeys.html#karnataka",
    "href": "Travel/Journeys.html#karnataka",
    "title": "Journeys",
    "section": "Karnataka",
    "text": "Karnataka"
  },
  {
    "objectID": "Travel/Journeys.html#kerala-and-tamil-nadu",
    "href": "Travel/Journeys.html#kerala-and-tamil-nadu",
    "title": "Journeys",
    "section": "Kerala and Tamil Nadu",
    "text": "Kerala and Tamil Nadu"
  },
  {
    "objectID": "Travel/Journeys.html#bankok-vietnam",
    "href": "Travel/Journeys.html#bankok-vietnam",
    "title": "Journeys",
    "section": "Bankok-Vietnam",
    "text": "Bankok-Vietnam"
  },
  {
    "objectID": "Travel/Journeys.html#china-honk-kong",
    "href": "Travel/Journeys.html#china-honk-kong",
    "title": "Journeys",
    "section": "China-Honk Kong",
    "text": "China-Honk Kong"
  },
  {
    "objectID": "Travel/Journeys.html#chennai-jaipur",
    "href": "Travel/Journeys.html#chennai-jaipur",
    "title": "Journeys",
    "section": "Chennai-Jaipur",
    "text": "Chennai-Jaipur"
  },
  {
    "objectID": "Travel/Journeys.html#delhi",
    "href": "Travel/Journeys.html#delhi",
    "title": "Journeys",
    "section": "Delhi",
    "text": "Delhi"
  },
  {
    "objectID": "Travel/Wiki.html",
    "href": "Travel/Wiki.html",
    "title": "Travel Wiki",
    "section": "",
    "text": "New Travel Wiki\n\nusing wikivoyage and wikitravel (and all their archives)\nusing wikipedia and many other places\nusing couchers.org, adding a button somewhere there for people to describe experiences\ngetting the openstreetmap community involved? maybe some back and forth there?\n\nAll of this rewritten by ai at different scales– this could even be an opportunity to use different hypertext protocols– maybe AI can finally start using that one where you can zoom in on words/paragraphs and they fit seamlessly into the page?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I grew up in a fishing village in the north of Scotland. I learned to be steady on my feet running over seaweed covered rocks. We moved to a farm. I learned to climb trees. Then I grew up and moved to the big city, and climbed on slimy rooftops and up gutters. Then I became civilized, and went to university.\nWhile studying for a Physics MSc. I worked for three years in a molecular biophysics laboratory developing microscopy techniques for studying DNA-protein interactions, including hardware and software engineering and a little bit of wetlab work. After taking a year out to further develop my programming skills I’m now working as a python programmer in a tech startup.\nI was civilized by artists in Leipzig, they took me in and told me how to survive in the 21st century. I’m now living in Vienna, continuing to learn these lessons."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "“Salamanders have their appointed Dwelling in Fire; Sylphs in the Air; Nymphs in the flowing Waters; and Gnomes in Earthen-burrows, but the creature whose substance is Bliss is everywhere at home. All sounds, even to the roaring of Lions, the screeching of the nightly Owls, the laments and groans of those entrapped in Hell, are as sweet Musick to her. All odours, even to the foulest stench of Corruption, are to her as the delight of roses and Lilies. All savours, even to the banquet-table of the Harpys of heathen lore, are as Sweet loaves and spiced Ale.\nWandering at noon through the Waste-Places of the world, it seems to her she is refreshed by Canopies of flocking Angels. The earnest seeker will look for her in All places, however dim and sordid, of this world or in the seven others. Thrust a keen Sword-blade through her and it will seem as a fountain of Divine and Pure pleasure.\nThese eyes, by Translation, have been given to see her ways; and an equal gift as revealed by Wisdom is sometimes granted the Child.”\n~ Jane Lead1\n\n\nSpreading the Sigmoid\n\n\n\n\n\nFootnotes\n\n\nMy subtitle is plagiarised from the Borges book where I was introduced to her. I have not been able to track down the original source for this, despite some attempts, so it could of course be a Borgesian invention.↩︎"
  },
  {
    "objectID": "Bib/All.html",
    "href": "Bib/All.html",
    "title": "Reading List",
    "section": "",
    "text": "I have, for the last years, been rating my reading. I have a database on my phone where I record things I have read.\nI have started adding things I want to read to this database.\nI’m happy enough with this at the moment, though I would like more integration and automation between this and other things."
  },
  {
    "objectID": "Bib/All.html#meta",
    "href": "Bib/All.html#meta",
    "title": "Reading List",
    "section": "Meta",
    "text": "Meta\nMetacognitive Note Taking for Creativity"
  },
  {
    "objectID": "Bib/All.html#important",
    "href": "Bib/All.html#important",
    "title": "Reading List",
    "section": "Important",
    "text": "Important\nConsilience DoNotPay – worlds first robot lawyer"
  },
  {
    "objectID": "Bib/All.html#xenosystems",
    "href": "Bib/All.html#xenosystems",
    "title": "Reading List",
    "section": "Xenosystems",
    "text": "Xenosystems\nFirms are not Aliens"
  },
  {
    "objectID": "Bib/All.html#blogs",
    "href": "Bib/All.html#blogs",
    "title": "Reading List",
    "section": "Blogs",
    "text": "Blogs\n\nInvesting\nA bunch of links I found just via this and eg this\n\n\nEA\nEA Blindspots and another ## Trivial Loads of fun links to trawl through in here"
  },
  {
    "objectID": "Bib/All.html#blogs-1",
    "href": "Bib/All.html#blogs-1",
    "title": "Reading List",
    "section": "Blogs",
    "text": "Blogs\nRise and Fall of Peer Review (followup)"
  },
  {
    "objectID": "Bib/All.html#tools",
    "href": "Bib/All.html#tools",
    "title": "Reading List",
    "section": "Tools",
    "text": "Tools\nSo some searches on hacker news. Search All Books with AI\nScinapse, academic search Semantic Scholar Elicit Connected Papers Tribler – seems like a pretty intense torrent harvester technology Fetch.io – streams torrents to you [BROKEN, but worth investigating] Inciteful, academnic graph viz\nAI Search tools:\nPerplexity\nWikipedia also has a list of academic search engines.\n\nSci-hub, libgen, zlibrary\nNote, append ‘.sci-hub.ru’ to paper sites!\nMirrors: * sci-hub.se * sci-hub.st * sci-hub.ru\nZlib Pirate Library Mirror\nNOTE: Anna from PiLiMi has some nice blog posts eg and could do with some help– this would be a good route back into the dark internet! > I’m nowadays also hanging out on the Discord of The Eye (IYKYK)."
  },
  {
    "objectID": "Bib/All.html#datasets",
    "href": "Bib/All.html#datasets",
    "title": "Reading List",
    "section": "Datasets",
    "text": "Datasets\nAcademic Torrents"
  },
  {
    "objectID": "Bib/All.html#bio-bio",
    "href": "Bib/All.html#bio-bio",
    "title": "Reading List",
    "section": "Bio Bio",
    "text": "Bio Bio\nSmybiosis and Evolution, Lynn Margulis Anna Tsing There is no such thing as a tree How not to think about cells– I kind of disagree with this but its a nice round-up of material Why is progress in Biology so Slow"
  },
  {
    "objectID": "Bib/All.html#statistics",
    "href": "Bib/All.html#statistics",
    "title": "Reading List",
    "section": "Statistics",
    "text": "Statistics\n\nEasy Overview in here, plus links\nGwern Overview\nTukey’s ‘Future of Data Analysis’"
  },
  {
    "objectID": "Bib/All.html#gerontology",
    "href": "Bib/All.html#gerontology",
    "title": "Reading List",
    "section": "Gerontology",
    "text": "Gerontology\n\nhttps://nintil.com/aging-solved-in-vitro"
  },
  {
    "objectID": "Bib/All.html#medicine-general",
    "href": "Bib/All.html#medicine-general",
    "title": "Reading List",
    "section": "Medicine General",
    "text": "Medicine General\n\nhttps://randomcriticalanalysis.com/2020/01/31/i-created-a-primer-on-fundamental-misconceptions-about-health-care/"
  },
  {
    "objectID": "Bib/All.html#citizen-science",
    "href": "Bib/All.html#citizen-science",
    "title": "Reading List",
    "section": "Citizen Science",
    "text": "Citizen Science\n\nhttps://slimemoldtimemold.com/"
  },
  {
    "objectID": "Bib/All.html#blogs-2",
    "href": "Bib/All.html#blogs-2",
    "title": "Reading List",
    "section": "Blogs",
    "text": "Blogs\nI should have loved biology – includes links to some good bio books > aka, The Eighth Day of Creation"
  },
  {
    "objectID": "Bib/All.html#tools-1",
    "href": "Bib/All.html#tools-1",
    "title": "Reading List",
    "section": "Tools",
    "text": "Tools\nArch wiki has a great list of applications– some of them are science focussed. Look through them for useful things."
  },
  {
    "objectID": "Bib/All.html#agi-ruin",
    "href": "Bib/All.html#agi-ruin",
    "title": "Reading List",
    "section": "AGI Ruin",
    "text": "AGI Ruin\nOriginal Post Containment Strategy Hanson-Yudkowsky Foom Debate * https://www.lesswrong.com/posts/Q4hLMDrFd8fbteeZ8/measuring-optimization-power * https://www.lesswrong.com/posts/spKYZgoh3RmhxMqyu/the-first-world-takeover * https://www.lesswrong.com/posts/gTNB9CQd5hnbkMxAG/protein-reinforcement-and-dna-consequentialism"
  },
  {
    "objectID": "Bib/All.html#articles",
    "href": "Bib/All.html#articles",
    "title": "Reading List",
    "section": "Articles",
    "text": "Articles\nManifesto"
  },
  {
    "objectID": "Bib/All.html#blogs-3",
    "href": "Bib/All.html#blogs-3",
    "title": "Reading List",
    "section": "Blogs",
    "text": "Blogs\nTensions of the Liberal Order Roots of Progress For our Posterity Permanent Problem Noah Pinion"
  },
  {
    "objectID": "Bib/All.html#acc",
    "href": "Bib/All.html#acc",
    "title": "Reading List",
    "section": "Acc",
    "text": "Acc\nMillions Must Die\n\nDysgenics\nQuilette, Cognitive Distortions"
  },
  {
    "objectID": "Bib/All.html#democracy",
    "href": "Bib/All.html#democracy",
    "title": "Reading List",
    "section": "Democracy",
    "text": "Democracy\nComputational Democracy (aka Polis) Computational Sociology (at above link) Network States – also check out Vitaliks post on the topic"
  },
  {
    "objectID": "Bib/All.html#futarchy",
    "href": "Bib/All.html#futarchy",
    "title": "Reading List",
    "section": "Futarchy",
    "text": "Futarchy\n\nFutarchy is a form of government proposed by economist Robin Hanson, in which elected officials define measures of national wellbeing, and prediction markets are used to determine which policies will have the most positive effect.\n\n\nPersonal context:\nKevin Mulligan introduced me to the GoodJudgementProject many moons ago. I got ‘involved’ (not very involved). Since then I have kept vague tabs on the topic, and one day intend to try getting into it.\nTo really try getting involved, I would have to dive into some of the learning material. For now I am happy to occasianlly dive into the reading.\nOne day I will dive into them again and try and make some bets.\n\n\nRead\n\nArbital guide to Bayes Rule\nGood Judgment Training\nGitcoin Grants\n\n\n\nLearn\n\nMetaculus Blog\n\nDeep learning ourselves into the unknown\n\nAugur\n\nThe Uber for Knowledge\n\n\n\n\nDo\n\nKalshi\nGood Judgement Project\nAugur\nPredictIt"
  },
  {
    "objectID": "Bib/All.html#economic-growth",
    "href": "Bib/All.html#economic-growth",
    "title": "Reading List",
    "section": "Economic Growth",
    "text": "Economic Growth\nI read conflicting views about this and tried to do a deeper dive by reading Harrawy and a textbook on Degrowth. I found the degrowth stuff quite unconvincing.\nGrumpy Economist has lots of Stuff\n\nReactionaries (Race and IQ and other things)\nhttp://www.lagriffedulion.f2s.com/index.html https://georgefrancis.substack.com/p/national-iq-is-the-best-predictor?utm_source=profile&utm_medium=reader2\nActually a nice one: https://thompsonj.substack.com/p/can-nations-have-iqs\n\n\nEconomic Growth in Five Figures Lant Pritchett 1\nThis has some good graphs that summarize the situation pretty thoroughly.\n\n\nThe Moral Foundations of Progress 0\nGood links to general stuff.\n“Our technological advancements used to entail new antibiotics, reductions in child mortality, and the capacity for self-determination. It is hard to compete with advances of that size, no matter how good our movies and kitchen appliances become.”\nNow they are trying to get me to join the bandwagon? “This all presents a compelling opportunity. Given its nascent state and the lack of serious full-time Progress Studies researchers, we–meaning anyone reading this document, meaning you–each have good odds of being able to substantially shape the course of this field. 25 How should we approach field-building? One approach is straightforward: publish good research, then label it Progress Studies, and simply assert that it is part of a new intellectual tradition. In contrast, my work here thus entails the beginning of an even more straightforward approach: 1. Robustly argue for foundational assumptions 2. Define operationalizations of key concepts 3. Set and enforce epistemic norms”\nQuite tempting actually.\n\n\nOur World in Data\nhas tonnes of stuff and are generally the best combination of gung-ho and data-heavy.\nSee the thread about drama with Justin Hickel for some relevant (and juicy) context.\n\n\nAgainst Wage Stagnation\nI would say that a huge amount of focus is placed on the situation in the US. There is some sense to this since they are leading the charge in GDP, but it should not be over-emphasized.\nReview\n\n\nDevelopment\nI read a lot about development. I want to organize my thoughts and my reading about this a little better.\n\n\nEconomic Growth\nAgain and again I see the idea that economic growth is good, that it drags people out of poverty, that it improves quality of life.\nMore importantly, it often seems like all the things that people want correlate with economic growth. So, even if you are unsatisfied with it as a metric for human wellbeing or happiness or anything else, finding another way of measuring what you ‘really want’ would be a waste of time because GDP already measures what you think you really want to measure. And there is already a tonne of research literature about it, so trying to create a new index and create a new body of literature on your new, improved index would be a huge waste of time.\nOf course if you can invent a wellbeing index that doesn’t correlate strongly with GDP then you will have something significant. But such a thing doesn’t seem to exist.\nHere is a good article that covers a lot of this stuff quite nicely: Economic Growth in 5 Figures.\nThere are also various things from eg. Our World in Data that cover this.\n\n\nThe issue\nThe issue is, many of my dear friends seem to disagree about this. But whenever I try to get to the heart of the disagreement, I get lost.\n\n\nCurrent work\nRead Donna Haraway’s Staying With the Trouble and try to see where the biggest points of difference between my worldview and hers are.\n\n\nOther reading\nI want to read Caliban and the Witch again, I have important disagreements with some of it. I want to read some books by Iam Morris. Though they seem to be largely things I would agree with, I want to check my methods and facts."
  },
  {
    "objectID": "Bib/All.html#history",
    "href": "Bib/All.html#history",
    "title": "Reading List",
    "section": "History",
    "text": "History\nIam Morris Human Accomplishment: The Pursuit of Excellence in the Arts and Sciences, 800 B.C. to 1950 this book looks like a good resource in terms of the methodology\n\nBlogs\nA collection of unmitigated pedantry, eg, Logistics III"
  },
  {
    "objectID": "Bib/All.html#misc",
    "href": "Bib/All.html#misc",
    "title": "Reading List",
    "section": "Misc",
    "text": "Misc\nCenter for Strategic Translation"
  },
  {
    "objectID": "Bib/All.html#general",
    "href": "Bib/All.html#general",
    "title": "Reading List",
    "section": "General",
    "text": "General\nRead Wittgenstein & Popper! Effective Aesthetics: Nietzschian Perfectionism Meets EA"
  },
  {
    "objectID": "Bib/All.html#accelerationism",
    "href": "Bib/All.html#accelerationism",
    "title": "Reading List",
    "section": "Accelerationism",
    "text": "Accelerationism\n\nhttps://web.archive.org/web/20190530072815/http://xynchroni.city/posts/22"
  },
  {
    "objectID": "Bib/All.html#misc-1",
    "href": "Bib/All.html#misc-1",
    "title": "Reading List",
    "section": "Misc",
    "text": "Misc\nEvil Gwern has some hot takes: * https://fantasticanachronism.com/2022/10/10/against-effective-altruism/"
  },
  {
    "objectID": "Bib/All.html#ontology",
    "href": "Bib/All.html#ontology",
    "title": "Reading List",
    "section": "Ontology",
    "text": "Ontology\n\nrobot ontology https://eigenrobot.substack.com/p/the-map-is-of-the-territory"
  },
  {
    "objectID": "Bib/All.html#psychedelics",
    "href": "Bib/All.html#psychedelics",
    "title": "Reading List",
    "section": "Psychedelics",
    "text": "Psychedelics\nEverything from QRI"
  },
  {
    "objectID": "Bib/Blogs.html",
    "href": "Bib/Blogs.html",
    "title": "Blogs",
    "section": "",
    "text": "https://doubleloop.net/\nVim Modes Transition Diagram. AWS in a sentence: all AWS services described in a couple of sentences."
  },
  {
    "objectID": "Bib/Blogs.html#cute-tools",
    "href": "Bib/Blogs.html#cute-tools",
    "title": "Blogs",
    "section": "Cute Tools",
    "text": "Cute Tools\nMinimalist pixel editor"
  },
  {
    "objectID": "Bib/Cleanup.html",
    "href": "Bib/Cleanup.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "Using Obsidian to take care of my knowledge.\nI am starting to use it now just for simple note-taking, and I will learn to use more and more of its features over time.\nIn particular I wan’t to organize my reading, my bookmarks, and my projects."
  },
  {
    "objectID": "Bib/Cleanup.html#research",
    "href": "Bib/Cleanup.html#research",
    "title": "Fergus Fettes",
    "section": "Research",
    "text": "Research\nRecently I have gotten back into reading widely and I think I would like to try communicating my ideas some more. Maybe even get back into research.\nI’m not sure exactly what research I would want to do, but I can see some general principles: * use advanced technology > I feel like scientists are still missing a lot of tricks w.r.t what is possible with modern methods. If I am going to go back into science I want to make sure I am up to speed on the latest tech * be meticulous > I would do a thorough literature review of my topic area and organize a lot of reading * do something you love > I love biology\n\nResearch Plans\nI want to make some general notes about the thing I find most interesting and promising.\nI would love to work on genetic engineering. There are a lot of problems that can presumably be addressed in this way (and only in this way)– the most obvious is perhaps childbirth. This is likely easily treatable and would contribute enormously to human wellbeing (both directly and indirectly through increased birthrates)."
  },
  {
    "objectID": "Bib/Farm.html",
    "href": "Bib/Farm.html",
    "title": "Farm Life Reading and Resources",
    "section": "",
    "text": "Auctions and Markets\ni-bidder\n\n\nBuild\nBuild List (also read further in discussion on HN) How to Glue This to That"
  },
  {
    "objectID": "Bib/Jobs.html",
    "href": "Bib/Jobs.html",
    "title": "Job Boards etc",
    "section": "",
    "text": "Meta\nJob Board Search curated list of job boards, eg this one for 4-day work weeks\n\n\nReading/Blogs\nbillable stuff eg Jonathan Stark\nMaybe worth reading some of this if/when you want to set up as freelance.\n\n\nBio Startups\nI’d love to work in some bio startups for a while, see if there is anything good there.\nStarting point?\nMisfit Mammoth mammoth biosciences, CRISPR bioengineering in Brisbane."
  },
  {
    "objectID": "Bib/MiscQuotes.html",
    "href": "Bib/MiscQuotes.html",
    "title": "Miscellaneous Quotes",
    "section": "",
    "text": "I’ve seen things you people wouldn’t believe. Attack ships on fire off the shoulder of Orion. I watched C-beams… glitter in the dark near the Tannhouser Gate. All those… moments will be lost… in time… like tears… in rain. Time… to die"
  },
  {
    "objectID": "Bib/Orgs.html",
    "href": "Bib/Orgs.html",
    "title": "Interesting Orgs",
    "section": "",
    "text": "https://www.britainremade.co.uk/ https://www.plurality.institute/"
  },
  {
    "objectID": "Bib/PictureBooks.html",
    "href": "Bib/PictureBooks.html",
    "title": "Picture Books",
    "section": "",
    "text": "Tyler Cohen recommends picture books as great value for money. I’ll list some recommendataions here in case I ever have some spare cash.\n\nVanishing Asia: Three Volume Set, Kevin Kelly"
  },
  {
    "objectID": "OldPosts/genetics_ideas.html",
    "href": "OldPosts/genetics_ideas.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "My original genetics idea was psychedelic walnuts. This one can be fleshed out in mor edetail at any point.\nAnother one I am fond of, but need to more research into to recall the exact science behind it is Glowing Zebra Women. There was something about the X chromosome during development, where there end up being these 1 inch bands all across womens bodies of genetically disctinct cell types. Need to find out the details.\nOrnamental beetles. The colors are obvious. Other features that can be nice would be:\n\n\nthe general beetles would be motionless, and just grip onto fabrics. However it might be nice to have beetles that move uphill or towards a particular color light. Very very slowly.\nthey are generally flightless as well, but they could be engineered to spontaneously fly up for a few inches and down again every hour or so."
  },
  {
    "objectID": "Study/gettingstartedinalignment.html",
    "href": "Study/gettingstartedinalignment.html",
    "title": "Fergus Fettes",
    "section": "",
    "text": "getting started in alignment research might take some time, Im guessing 6-24 months depending on your background and how muhc time you dedicate. Here are some examples of things you could spend time on. Nothing on this list is a requirement, nor are you expected to do all this. These are just examples of things that you could spend time on. - Use this website to keep track of opportunities. Apply liberally, dont expect to get accepted to the majority of things. Other sources (will overlap): - https://www.agisafetyfundamentals.com/opportunities - AI safety support slack #opportunities channel - Do the AGISF. The curriciulum is open, so you can do it by your own or with a friend. - Probably will want to learn some practical ML. This Course I reccomend. - spend a minority of time reading stuff on alignment forum / lesswrong that you find interesting. Start building an inside model - Use the AI safety support resources: They have a newsletter, a list of resources. Furthermore, you can read JJ’s posts on “Getting started independently in AI safety” and “The application is not the applicant”. - I reccomend the https://alignmentjam.com/ hackathons if you wanna get started doing something. Might need some ML first. - General skillbuilding is great if you enjoy it. Doing supervised research or internship can be a good use of your time even if its non-alignment related. - Take care of yourself. Spend as much time on these things as you find fun/interesting/meaningful and can afford and no more :)\n\nBibliography\nTaskonomy"
  }
]